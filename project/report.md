# Hadoop and Spark Clusters with Raspberry Pi

Akshay Kowshik, akowshik@iu.edu [fa19-516-162](https://github.com/cloudmesh-community/fa19-516-150) working on Hadoop.
Daivik Uggehalli Dayanand, daugge@iu.edu [fa19-516-158](https://github.com/cloudmesh-community/fa19-516-162) working on Spark.

## Abstract
Deployment of Hadoop and Spark on Raspberry Pi Clusters which involves:
* Developing a REST service that submits stuff to the cluster remotely.

## Introduction

## Related Work

## Architecture

## Technologies used
* cm-burn
* cloudmesh-inventory
* Python
* REST
* HDFS
* Hadoop
* Spark

## Workbreakdown

## Benchmark and Evaluation 
* Use PyTests leveraging Stopwatch

## Conclusion

## References
